{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchaudio\n",
      "  Obtaining dependency information for torchaudio from https://files.pythonhosted.org/packages/3e/c4/bfaa620bba2e53e7707295bcc07b65871a52efe84510340ad79ce6a69be0/torchaudio-2.1.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached torchaudio-2.1.1-cp311-cp311-win_amd64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: transformers in c:\\users\\neste\\appdata\\local\\anaconda3\\lib\\site-packages (4.32.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\neste\\appdata\\local\\anaconda3\\lib\\site-packages (3.7.2)\n",
      "Requirement already satisfied: torch in c:\\users\\neste\\appdata\\local\\anaconda3\\lib\\site-packages (2.1.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\neste\\appdata\\local\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\neste\\appdata\\local\\anaconda3\\lib\\site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\neste\\appdata\\local\\anaconda3\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\neste\\appdata\\local\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\neste\\appdata\\local\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\neste\\appdata\\local\\anaconda3\\lib\\site-packages (from torch) (2023.4.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in c:\\users\\neste\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (0.15.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\neste\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\neste\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\neste\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\neste\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\users\\neste\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\neste\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\neste\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (0.3.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\neste\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\neste\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\neste\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\neste\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\neste\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\neste\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\neste\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\neste\\appdata\\local\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\neste\\appdata\\local\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\neste\\appdata\\local\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\neste\\appdata\\local\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\neste\\appdata\\local\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\neste\\appdata\\local\\anaconda3\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\neste\\appdata\\local\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\neste\\appdata\\local\\anaconda3\\lib\\site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\neste\\appdata\\local\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Using cached torchaudio-2.1.1-cp311-cp311-win_amd64.whl (2.3 MB)\n",
      "Installing collected packages: torchaudio\n",
      "Successfully installed torchaudio-2.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torchaudio transformers matplotlib torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement transfomrers (from versions: none)\n",
      "ERROR: No matching distribution found for transfomrers\n"
     ]
    }
   ],
   "source": [
    "pip install transfomrers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c964ff8ca74e41379bdb3e4d0e9dba8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/1.60k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\neste\\AppData\\Local\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\neste\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54749cac53c948baa133023dc01c32de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/378M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/wav2vec2-base-960h were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6bde3cf4962488ea7e28575fc94b6e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)rocessor_config.json:   0%|          | 0.00/159 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5849518bcc74e3895eeb483af484350",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/163 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46824b12a2194fa88aeb8304a2122c66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.json:   0%|          | 0.00/291 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cae8d7db528412e9e21e5299deff29e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "from torchaudio.transforms import Resample\n",
    "\n",
    "# Load pre-trained Wav2Vec model and processor\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "\n",
    "# Example: Pre-process and transcribe audio file\n",
    "def transcribe_audio(audio_path):\n",
    "    # Load audio file\n",
    "    waveform, sample_rate = torchaudio.load(audio_path)\n",
    "    \n",
    "    # Resample if needed\n",
    "    if sample_rate != processor.feature_extractor.sampling_rate:\n",
    "        resampler = Resample(orig_freq=sample_rate, new_freq=processor.feature_extractor.sampling_rate)\n",
    "        waveform = resampler(waveform)\n",
    "\n",
    "    # Tokenize input and get logits\n",
    "    input_values = processor(waveform.squeeze().numpy(), return_tensors=\"pt\").input_values\n",
    "\n",
    "    # Make prediction\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_values).logits\n",
    "\n",
    "    # Get predicted ids\n",
    "    predicted_ids = torch.argmax(logits, dim=-1)\n",
    "\n",
    "    # Decode to text\n",
    "    transcription = processor.batch_decode(predicted_ids)[0]\n",
    "    return transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "audio_path = \"path/to/your/audio/file.wav\"\n",
    "result = transcribe_audio(audio_path)\n",
    "print(\"Transcription:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "<class 'torchaudio.datasets.speechcommands.SPEECHCOMMANDS'> is not a generic class",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Load an example audio file from torchaudio's SpeechCommands dataset\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m waveform, sample_rate, label, speaker_id, utterance_number \u001b[38;5;241m=\u001b[39m torchaudio\u001b[38;5;241m.\u001b[39mdatasets\u001b[38;5;241m.\u001b[39mSPEECHCOMMANDS[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Display information about the audio file\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWaveform: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwaveform\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\typing.py:358\u001b[0m, in \u001b[0;36m_tp_cache.<locals>.decorator.<locals>.inner\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    357\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# All real errors (not unhashable args) are raised below.\u001b[39;00m\n\u001b[1;32m--> 358\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\typing.py:1838\u001b[0m, in \u001b[0;36mGeneric.__class_getitem__\u001b[1;34m(cls, params)\u001b[0m\n\u001b[0;32m   1836\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m prepare \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1837\u001b[0m         params \u001b[38;5;241m=\u001b[39m prepare(\u001b[38;5;28mcls\u001b[39m, params)\n\u001b[1;32m-> 1838\u001b[0m _check_generic(\u001b[38;5;28mcls\u001b[39m, params, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__parameters__))\n\u001b[0;32m   1840\u001b[0m new_args \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1841\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param, new_arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m__parameters__, params):\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\typing.py:283\u001b[0m, in \u001b[0;36m_check_generic\u001b[1;34m(cls, parameters, elen)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check correct count for parameters of a generic cls (internal helper).\u001b[39;00m\n\u001b[0;32m    279\u001b[0m \n\u001b[0;32m    280\u001b[0m \u001b[38;5;124;03mThis gives a nice error message in case of count mismatch.\u001b[39;00m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m elen:\n\u001b[1;32m--> 283\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a generic class\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    284\u001b[0m alen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(parameters)\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m alen \u001b[38;5;241m!=\u001b[39m elen:\n",
      "\u001b[1;31mTypeError\u001b[0m: <class 'torchaudio.datasets.speechcommands.SPEECHCOMMANDS'> is not a generic class"
     ]
    }
   ],
   "source": [
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load an example audio file from torchaudio's SpeechCommands dataset\n",
    "waveform, sample_rate, label, speaker_id, utterance_number = torchaudio.datasets.SPEECHCOMMANDS[0]\n",
    "\n",
    "# Display information about the audio file\n",
    "print(f\"Waveform: {waveform}\")\n",
    "print(f\"Sample rate: {sample_rate}\")\n",
    "print(f\"Label: {label}\")\n",
    "print(f\"Speaker ID: {speaker_id}\")\n",
    "print(f\"Utterance Number: {utterance_number}\")\n",
    "\n",
    "# Plot the waveform\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(waveform.t().numpy())\n",
    "plt.title(\"Waveform\")\n",
    "plt.xlabel(\"Sample\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.show()\n",
    "\n",
    "# Apply some transformations and plot the spectrogram\n",
    "transform = T.MelSpectrogram(sample_rate=sample_rate, n_mels=128)\n",
    "spectrogram = transform(waveform)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.imshow(spectrogram[0].numpy(), cmap='viridis', aspect='auto', origin='lower')\n",
    "plt.title(\"Spectrogram\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Mel Frequency Bin\")\n",
    "plt.colorbar(format=\"%+2.0f dB\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
