{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import MobileNetV2\n",
    "from keras.layers import GlobalAveragePooling2D, Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Data loading\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    '/home/dragon/repos/datasets/train',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    '/home/dragon/repos/datasets/val',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Model building\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False)\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.samples // val_generator.batch_size\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model.save('skin_disease_detection_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Data loading\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    '/home/dragon/repos/datasets/train',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    '/home/dragon/repos/datasets/val',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Load pre-trained ResNet50 model without the top classification layer\n",
    "base_model = ResNet50(weights='imagenet', include_top=False)\n",
    "\n",
    "# Add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Add a fully connected layer with 256 hidden units and ReLU activation\n",
    "x = Dense(256, activation='relu')(x)\n",
    "\n",
    "# Add a final classification layer with softmax activation\n",
    "predictions = Dense(9, activation='softmax')(x)\n",
    "\n",
    "# Combine the base model and the new classification layers\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the layers of the base model (only train the new classification layers)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=10,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.samples // val_generator.batch_size\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(val_generator, steps=val_generator.samples // val_generator.batch_size)\n",
    "print(f'Validation loss: {loss:.4f}')\n",
    "print(f'Validation accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from flask import Flask, request, jsonify, render_template\n",
    "from tensorflow import keras\n",
    "\n",
    "app = Flask(__name__)\n",
    "model = keras.models.load_model('skin_disease_detection_model.h5')\n",
    "target_size = (224, 224)  # Adjust based on your model's input shape\n",
    "\n",
    "def preprocess_image(image):\n",
    "    image = image.resize(target_size)\n",
    "    image = np.array(image) / 255.0  # Normalize pixel values\n",
    "    image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
    "    return image\n",
    "\n",
    "def predict_image(image):\n",
    "    preprocessed_image = preprocess_image(image)\n",
    "    predictions = model.predict(preprocessed_image)\n",
    "    predicted_class = np.argmax(predictions, axis=-1)\n",
    "    return predicted_class\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/upload', methods=['POST'])\n",
    "def upload_image():\n",
    "    if 'file' not in request.files:\n",
    "        return jsonify({'error': 'No file part'}), 400\n",
    "\n",
    "    file = request.files['file']\n",
    "    if file.filename == '':\n",
    "        return jsonify({'error': 'No selected file'}), 400\n",
    "\n",
    "    if file:\n",
    "        image = Image.open(file)\n",
    "        predicted_class = predict_image(image)\n",
    "        return render_template('index.html', predicted_class=int(predicted_class))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.2791917281491416\n",
      "Epoch 2/10, Loss: 0.7135993646723884\n",
      "Epoch 3/10, Loss: 0.4265538305044174\n",
      "Epoch 4/10, Loss: 0.3351859711110592\n",
      "Epoch 5/10, Loss: 0.19149909647447722\n",
      "Epoch 6/10, Loss: 0.1682263586137976\n",
      "Epoch 7/10, Loss: 0.09487607622785228\n",
      "Epoch 8/10, Loss: 0.07281158146049295\n",
      "Epoch 9/10, Loss: 0.11417909039716635\n",
      "Epoch 10/10, Loss: 0.14924550987780094\n",
      "Accuracy on test set: 69.73%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "import os\n",
    "\n",
    "# Set device (GPU if available, else CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define transforms for data preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Define paths to train and test data\n",
    "train_data_path = '/home/oem/Downloads/whatsapp/archive/DATA/train'\n",
    "test_data_path = '/home/oem/Downloads/whatsapp/archive/DATA/testing'\n",
    "\n",
    "# Load train and test datasets\n",
    "train_dataset = datasets.ImageFolder(train_data_path, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(test_data_path, transform=transform)\n",
    "\n",
    "# Define data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "# Define CNN model architecture\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.model = models.resnet18(pretrained=True)  # You can choose a different pretrained model if needed\n",
    "        in_features = self.model.fc.in_features\n",
    "        self.model.fc = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Initialize the model\n",
    "num_classes = len(train_dataset.classes)\n",
    "model = CustomModel(num_classes).to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on test set: {(100 * correct / total):.2f}%\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'model.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 69.73%\n"
     ]
    }
   ],
   "source": [
    "##################33\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "# Set device (GPU if available, else CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define transforms for data preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Define paths to train and test data\n",
    "train_data_path = '/home/oem/Downloads/whatsapp/archive/DATA/train'\n",
    "test_data_path = '/home/oem/Downloads/whatsapp/archive/DATA/testing'\n",
    "\n",
    "# Load train and test datasets\n",
    "train_dataset = datasets.ImageFolder(train_data_path, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(test_data_path, transform=transform)\n",
    "\n",
    "# Define data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "# Define CNN model architecture\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.model = resnet18(pretrained=True)  # Load pre-trained ResNet18 model\n",
    "        num_ftrs = self.model.fc.in_features\n",
    "        self.model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Initialize the model\n",
    "num_classes = len(train_dataset.classes)\n",
    "model = CustomModel(num_classes).to(device)\n",
    "\n",
    "# Load the trained model weights\n",
    "MODEL_PATH = \"model.pt\"\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "# Define loss function and optimizer (optional if not training further)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# No need to train the model further if using pre-trained weights\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on test set: {(100 * correct / total):.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      " * Restarting with stat\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/oem/.local/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/oem/.local/lib/python3.10/site-packages/traitlets/config/application.py\", line 1074, in launch_instance\n",
      "    app.initialize(argv)\n",
      "  File \"/home/oem/.local/lib/python3.10/site-packages/traitlets/config/application.py\", line 118, in inner\n",
      "    return method(app, *args, **kwargs)\n",
      "  File \"/home/oem/.local/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 692, in initialize\n",
      "    self.init_sockets()\n",
      "  File \"/home/oem/.local/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 331, in init_sockets\n",
      "    self.shell_port = self._bind_socket(self.shell_socket, self.shell_port)\n",
      "  File \"/home/oem/.local/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 253, in _bind_socket\n",
      "    return self._try_bind_socket(s, port)\n",
      "  File \"/home/oem/.local/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 229, in _try_bind_socket\n",
      "    s.bind(\"tcp://%s:%i\" % (self.ip, port))\n",
      "  File \"/home/oem/.local/lib/python3.10/site-packages/zmq/sugar/socket.py\", line 302, in bind\n",
      "    super().bind(addr)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 564, in zmq.backend.cython.socket.Socket.bind\n",
      "  File \"zmq/backend/cython/checkrc.pxd\", line 28, in zmq.backend.cython.checkrc._check_rc\n",
      "zmq.error.ZMQError: Address already in use (addr='tcp://127.0.0.1:9002')\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oem/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, request, redirect, url_for, send_file\n",
    "from werkzeug.utils import secure_filename\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "import json\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "UPLOAD_FOLDER = 'uploads'\n",
    "RESULT_FOLDER = '/home/oem/repos/MachineLEarning-School/face detection/skin blemishes/results'\n",
    "ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg', 'gif'}\n",
    "MODEL_PATH = '/home/oem/repos/MachineLEarning-School/face detection/skin blemishes/best.pt'\n",
    "\n",
    "# Load the pre-trained YOLOv5 model\n",
    "model = YOLO(MODEL_PATH)\n",
    "\n",
    "def inference(image_path, result_folder):\n",
    "    try:\n",
    "        # Run inference on a single image\n",
    "        results = model(image_path)\n",
    "        result_data = []\n",
    "\n",
    "        for i, result in enumerate(results):\n",
    "            result_image_path = os.path.join(result_folder, f'result_{i}.jpg')\n",
    "            result.save(filename=result_image_path)\n",
    "            result_info = {\n",
    "                \"image_path\": result_image_path,\n",
    "                \"detections\": []\n",
    "            }\n",
    "\n",
    "            # Example: Extracting detected diseases from the model\n",
    "            detected_diseases = []  # Replace this with the actual detected disease information\n",
    "            for det in result.pred:\n",
    "                class_label = model.names[int(det[-1])]\n",
    "                detected_diseases.append(class_label)\n",
    "            \n",
    "            # Append detected diseases to result_info\n",
    "            result_info[\"detected_diseases\"] = detected_diseases\n",
    "\n",
    "            for det in result.pred:\n",
    "                # Extract class label and confidence\n",
    "                class_label = model.names[int(det[-1])]\n",
    "                confidence = det[-2]\n",
    "\n",
    "                # Store detection information\n",
    "                detection_info = {\n",
    "                    \"class\": class_label,\n",
    "                    \"confidence\": confidence,\n",
    "                    \"box\": det[:4].tolist()  # Convert to list to serialize in JSON\n",
    "                }\n",
    "                result_info[\"detections\"].append(detection_info)\n",
    "\n",
    "            result_data.append(result_info)\n",
    "\n",
    "        # Serialize the result data to JSON\n",
    "        json_data = json.dumps(result_data, indent=4)\n",
    "        with open(os.path.join(result_folder, 'result.json'), 'w') as json_file:\n",
    "            json_file.write(json_data)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during inference: {e}\")\n",
    "\n",
    "def allowed_file(filename):\n",
    "    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/upload', methods=['POST'])\n",
    "def upload():\n",
    "    if 'file' not in request.files:\n",
    "        return redirect(url_for('index'))\n",
    "\n",
    "    file = request.files['file']\n",
    "\n",
    "    if file.filename == '':\n",
    "        return redirect(url_for('index'))\n",
    "\n",
    "    if file and allowed_file(file.filename):\n",
    "        try:\n",
    "            filename = secure_filename(file.filename)\n",
    "            file_path = os.path.join(UPLOAD_FOLDER, filename)\n",
    "            file.save(file_path)\n",
    "\n",
    "            # Perform inference on the uploaded image\n",
    "            inference(file_path, RESULT_FOLDER)\n",
    "\n",
    "            # Redirect to the result page\n",
    "            return redirect(url_for('result'))\n",
    "        except Exception as e:\n",
    "            print(f\"Error during file upload or inference: {e}\")\n",
    "            return redirect(url_for('index'))\n",
    "\n",
    "    return redirect(url_for('index'))\n",
    "\n",
    "@app.route('/result')\n",
    "def result():\n",
    "    return render_template('result.html')\n",
    "\n",
    "@app.route('/display_result')\n",
    "def display_result():\n",
    "    result_image_path = os.path.join(RESULT_FOLDER, 'result_0.jpg')\n",
    "    return send_file(result_image_path, mimetype='image/jpeg')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    os.makedirs(UPLOAD_FOLDER, exist_ok=True)\n",
    "    os.makedirs(RESULT_FOLDER, exist_ok=True)\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
